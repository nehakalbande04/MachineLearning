{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8XBX4Js-iLcT"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzSjupC-rlzm"
   },
   "source": [
    "# Objective of the task is to predict the Profit of the state based on the other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UJgt7Pe4hBL9"
   },
   "outputs": [],
   "source": [
    "# Your code to import numpy\n",
    "import numpy as np\n",
    "# Your code to import panda\n",
    "import pandas as pd\n",
    "# Your code to import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-PDHsuSxicT-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to read file\n",
    "dataset = pd.read_csv(\"50_Startups.csv\")\n",
    "# Your code to print sample data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27F819fqr0MK"
   },
   "source": [
    "# Separate the independednt and Dependent variables.\n",
    "# Profit is the dependedent variable\n",
    "\n",
    "## What is the role of the axis and inplace in following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LUXxD-gViltR"
   },
   "outputs": [],
   "source": [
    "y = np.asarray(dataset['Profit'].values.tolist())\n",
    "\n",
    "dataset.drop([\"Profit\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8d-0FfnsN0O"
   },
   "source": [
    "# We will convert  Categorical Variable values \"State\" to numbers with the One Hot Encoding Technique\n",
    "\n",
    "# Initially, we will counts value that the feature \"State\" can take.\n",
    "\n",
    "# Remember .value_counts() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "M3CB3Ct9i4an"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State\n",
       "New York      17\n",
       "California    17\n",
       "Florida       16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:,3].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WSSeKczss1U"
   },
   "source": [
    "# Replacing the three states by the numbers 1, 2, 3.\n",
    "# This is also called as the LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RonZ0XJVi7VO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend  State\n",
       "0   165349.20       136897.80        471784.10      2\n",
       "1   162597.70       151377.59        443898.53      1\n",
       "2   153441.51       101145.55        407934.54      3\n",
       "3   144372.41       118671.85        383199.62      2\n",
       "4   142107.34        91391.77        366168.42      3\n",
       "5   131876.90        99814.71        362861.36      2\n",
       "6   134615.46       147198.87        127716.82      1\n",
       "7   130298.13       145530.06        323876.68      3\n",
       "8   120542.52       148718.95        311613.29      2\n",
       "9   123334.88       108679.17        304981.62      1\n",
       "10  101913.08       110594.11        229160.95      3\n",
       "11  100671.96        91790.61        249744.55      1\n",
       "12   93863.75       127320.38        249839.44      3\n",
       "13   91992.39       135495.07        252664.93      1\n",
       "14  119943.24       156547.42        256512.92      3\n",
       "15  114523.61       122616.84        261776.23      2\n",
       "16   78013.11       121597.55        264346.06      1\n",
       "17   94657.16       145077.58        282574.31      2\n",
       "18   91749.16       114175.79        294919.57      3\n",
       "19   86419.70       153514.11             0.00      2\n",
       "20   76253.86       113867.30        298664.47      1\n",
       "21   78389.47       153773.43        299737.29      2\n",
       "22   73994.56       122782.75        303319.26      3\n",
       "23   67532.53       105751.03        304768.73      3\n",
       "24   77044.01        99281.34        140574.81      2\n",
       "25   64664.71       139553.16        137962.62      1\n",
       "26   75328.87       144135.98        134050.07      3\n",
       "27   72107.60       127864.55        353183.81      2\n",
       "28   66051.52       182645.56        118148.20      3\n",
       "29   65605.48       153032.06        107138.38      2\n",
       "30   61994.48       115641.28         91131.24      3\n",
       "31   61136.38       152701.92         88218.23      2\n",
       "32   63408.86       129219.61         46085.25      1\n",
       "33   55493.95       103057.49        214634.81      3\n",
       "34   46426.07       157693.92        210797.67      1\n",
       "35   46014.02        85047.44        205517.64      2\n",
       "36   28663.76       127056.21        201126.82      3\n",
       "37   44069.95        51283.14        197029.42      1\n",
       "38   20229.59        65947.93        185265.10      2\n",
       "39   38558.51        82982.09        174999.30      1\n",
       "40   28754.33       118546.05        172795.67      1\n",
       "41   27892.92        84710.77        164470.71      3\n",
       "42   23640.93        96189.63        148001.11      1\n",
       "43   15505.73       127382.30         35534.17      2\n",
       "44   22177.74       154806.14         28334.72      1\n",
       "45    1000.23       124153.04          1903.93      2\n",
       "46    1315.46       115816.21        297114.46      3\n",
       "47       0.00       135426.92             0.00      1\n",
       "48     542.05        51743.15             0.00      2\n",
       "49       0.00       116983.80         45173.06      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.replace(to_replace=[\"California\",\"New York\", \"Florida\"], value=[1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQungUWgtBIL"
   },
   "source": [
    "# We will create 3 more columns for the three states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sEz2FMUfi9gK"
   },
   "outputs": [],
   "source": [
    "dataset[\"California\"] = dataset.iloc[:, 3]\n",
    "dataset[\"New York\"] = dataset.iloc[:,3]\n",
    "dataset[\"Florida\"] = dataset.iloc[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unUvog8WtNpu"
   },
   "source": [
    "# Check how the dataset looks now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "98teOtjzjIp2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>California</th>\n",
       "      <th>New York</th>\n",
       "      <th>Florida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State  California  \\\n",
       "0  165349.20       136897.80        471784.10    New York    New York   \n",
       "1  162597.70       151377.59        443898.53  California  California   \n",
       "2  153441.51       101145.55        407934.54     Florida     Florida   \n",
       "3  144372.41       118671.85        383199.62    New York    New York   \n",
       "4  142107.34        91391.77        366168.42     Florida     Florida   \n",
       "\n",
       "     New York     Florida  \n",
       "0    New York    New York  \n",
       "1  California  California  \n",
       "2     Florida     Florida  \n",
       "3    New York    New York  \n",
       "4     Florida     Florida  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print few samples of dataset.\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoLuUTSBtVZj"
   },
   "source": [
    "# Performing one hot encoding for the column Calfornia.\n",
    "## Replace text 'California' with 1 and others with 0 for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZABX9aatjLdw"
   },
   "outputs": [],
   "source": [
    "dataset.loc[dataset[\"California\"]!=\"California\", \"California\"] = 0\n",
    "dataset.loc[dataset[\"California\"]==\"California\", \"California\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rrqbptyntrgw"
   },
   "source": [
    "# Perform the one hot encoding for New York and the Florida column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6zcJTPVxjPYk"
   },
   "outputs": [],
   "source": [
    "# Your code to perform one hot encoding for New York column.\n",
    "dataset.loc[dataset[\"New York\"]!=\"New York\", \"New York\"] = 0\n",
    "dataset.loc[dataset[\"New York\"]==\"New York\", \"New York\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XnoCxjbejSmN"
   },
   "outputs": [],
   "source": [
    "# Your code to perform one hot encoding for Florida column.\n",
    "dataset.loc[dataset[\"Florida\"]!=\"Florida\", \"Florida\"] = 0\n",
    "dataset.loc[dataset[\"Florida\"]==\"Florida\", \"Florida\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of9U6eX4uGwj"
   },
   "source": [
    "# Now look at the dataset\n",
    "## Can you find the state name from numbers in last three columns only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4JUs_zpLjV_e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>California</th>\n",
       "      <th>New York</th>\n",
       "      <th>Florida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State California New York  \\\n",
       "0  165349.20       136897.80        471784.10    New York          0        1   \n",
       "1  162597.70       151377.59        443898.53  California          1        0   \n",
       "2  153441.51       101145.55        407934.54     Florida          0        0   \n",
       "3  144372.41       118671.85        383199.62    New York          0        1   \n",
       "4  142107.34        91391.77        366168.42     Florida          0        0   \n",
       "\n",
       "  Florida  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print sample\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dm80EXTuX8w"
   },
   "source": [
    "# Drop the State and one of the three states column.\n",
    "## Question - Why we are dropping one column for the state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hAFgpUrmjZbp"
   },
   "outputs": [],
   "source": [
    "# Your code to drop State and Florida column\n",
    "\n",
    "dataset.drop([\"State\",\"Florida\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4kE329ku90q"
   },
   "source": [
    "# Lets's check the dataset again.\n",
    "## Question - Can you guess the name of three states from the numbers (1/0) in last two column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9JtxL7LPj-Ze"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>California</th>\n",
       "      <th>New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend California New York\n",
       "0  165349.20       136897.80        471784.10          0        1\n",
       "1  162597.70       151377.59        443898.53          1        0\n",
       "2  153441.51       101145.55        407934.54          0        0\n",
       "3  144372.41       118671.85        383199.62          0        1\n",
       "4  142107.34        91391.77        366168.42          0        0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print sample dataset.\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIQepd2JvPmH"
   },
   "source": [
    "# Let's further process independent variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KuLd1d0ukA_E"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(dataset.values.tolist()).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jbjZBzrwPWM"
   },
   "source": [
    "# Print the shapes of the aray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NWMcIEalkHJp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 5)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# Your code to print the shape of X\n",
    "print(X.shape)\n",
    "# Your code to print the shape of y\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mkuT1JvwXQS"
   },
   "source": [
    "# Change the shape of the dependent variable to (len(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kkOIedKLkJsS"
   },
   "outputs": [],
   "source": [
    "# Your code to change the shape of the y to (len(y), 1)\n",
    "y = y.reshape(len(y),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "086Arswgwifr"
   },
   "source": [
    "# Perform feature scaling\n",
    "## We will study this in detail in class.\n",
    "## For now, guess what following code is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3xY_jX90kqWe"
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(X.shape[1]-2):\n",
    "    X[:,i] = (X[:,i] - int(np.mean(X[:,i])))/np.std(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "d5X_d-T-k2_f"
   },
   "outputs": [],
   "source": [
    "y = (y - int(np.mean(y)))/np.std(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDibPJ8Xw6qJ"
   },
   "source": [
    "### Adding the feature X0 = 1, so we have the equation: y =  theta[0] * X0 + theta[1] * X1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6IJwREnmk53K"
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X,np.ones((50,1))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xeqVGkmxNqW"
   },
   "source": [
    "# Let's see X, y and their shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "F72giE7Zk8Xc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.01642504e+00  5.60775975e-01  2.15394390e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.95587388e+00  1.08282964e+00  1.92360120e+00  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 1.75437728e+00 -7.28233968e-01  1.62652848e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 1.55479724e+00 -9.63415706e-02  1.42221104e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.50495075e+00 -1.07989629e+00  1.28152852e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 1.27981356e+00 -7.76216010e-01  1.25421127e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.34007995e+00  9.32170269e-01 -6.88149122e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 1.24507020e+00  8.72003071e-01  9.32186786e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 1.03038241e+00  9.86975162e-01  8.30887717e-01  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.09183275e+00 -4.56617186e-01  7.76108248e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 6.20411795e-01 -3.87576029e-01  1.49808075e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 5.93098965e-01 -1.06551653e+00  3.19834431e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 4.43273419e-01  2.15472124e-01  3.20618249e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 4.02091150e-01  5.10202013e-01  3.43957596e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 1.01719429e+00  1.26922245e+00  3.75743081e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 8.97926670e-01  4.58909136e-02  4.19219510e-01  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 9.44547430e-02  9.14147979e-03  4.40447032e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 4.60733675e-01  8.55689379e-01  5.91017531e-01  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 3.96738485e-01 -2.58442307e-01  6.92992870e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 2.79455197e-01  1.15985963e+00 -1.74312617e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 5.57396340e-02 -2.69564591e-01  7.23926803e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 1.02737147e-01  1.16920915e+00  7.32788599e-01  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 6.02012518e-03  5.18726249e-02  7.62376684e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.36187177e-01 -5.62188208e-01  7.74349716e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 7.31281480e-02 -7.95446107e-01 -5.81938489e-01  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-1.99298141e-01  6.56512199e-01 -6.03515917e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 3.53837501e-02  8.21740976e-01 -6.35834687e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-3.55054466e-02  2.35091603e-01  1.17427197e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-1.68779170e-01  2.21016356e+00 -7.67188629e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.78594993e-01  1.14247983e+00 -8.58132855e-01  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-2.58060822e-01 -2.05605599e-01 -9.90356358e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-2.76944684e-01  1.13057697e+00 -1.01441864e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-2.26935128e-01  2.83946873e-01 -1.36244897e+00  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-4.01115378e-01 -6.59300973e-01  2.98180513e-02  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-6.00668575e-01  1.31055831e+00 -1.87781008e-03  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-6.09736394e-01 -1.30863447e+00 -4.54923508e-02  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-9.91556606e-01  2.05947751e-01 -8.17617655e-02  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-6.52518763e-01 -2.52597096e+00 -1.15607448e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.17716400e+00 -1.99724731e+00 -2.12784058e-01  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-7.73806812e-01 -1.38309850e+00 -2.97582468e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-9.89563468e-01 -1.00877158e-01 -3.15785075e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.00852017e+00 -1.32077275e+00 -3.84551599e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.10209201e+00 -9.06914474e-01 -5.20595152e-01  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.28112009e+00  2.17704585e-01 -1.44960388e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-1.13429185e+00  1.20644242e+00 -1.50907337e+00  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.60033681e+00  1.01276996e-01 -1.72739917e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-1.59339967e+00 -1.99298681e-01  7.11123282e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.62234847e+00  5.07744936e-01 -1.74312617e+00  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.61041980e+00 -2.50938578e+00 -1.74312617e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-1.62234847e+00 -1.57202446e-01 -1.36998392e+00  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]]\n",
      "(50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Your code to print sample values in X\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wiCADV4Xk-40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.01121935]\n",
      " [ 1.99944599]\n",
      " [ 1.98085827]\n",
      " [ 1.77664326]\n",
      " [ 1.35775614]\n",
      " [ 1.12726565]\n",
      " [ 1.10549657]\n",
      " [ 1.09622589]\n",
      " [ 1.00748569]\n",
      " [ 0.94603849]\n",
      " [ 0.85486277]\n",
      " [ 0.80818358]\n",
      " [ 0.74117086]\n",
      " [ 0.55876554]\n",
      " [ 0.51604239]\n",
      " [ 0.44873569]\n",
      " [ 0.37545172]\n",
      " [ 0.33478716]\n",
      " [ 0.30713202]\n",
      " [ 0.26978867]\n",
      " [ 0.16195124]\n",
      " [-0.01751782]\n",
      " [-0.04159662]\n",
      " [-0.08215341]\n",
      " [-0.08671344]\n",
      " [-0.11547707]\n",
      " [-0.15735062]\n",
      " [-0.17552631]\n",
      " [-0.21878153]\n",
      " [-0.2758662 ]\n",
      " [-0.30260858]\n",
      " [-0.36411142]\n",
      " [-0.36550788]\n",
      " [-0.38177109]\n",
      " [-0.38342819]\n",
      " [-0.3892749 ]\n",
      " [-0.53391559]\n",
      " [-0.55293888]\n",
      " [-0.77148132]\n",
      " [-0.77707766]\n",
      " [-0.84639533]\n",
      " [-0.85744966]\n",
      " [-1.01534864]\n",
      " [-1.05894419]\n",
      " [-1.17319297]\n",
      " [-1.18006622]\n",
      " [-1.5669061 ]\n",
      " [-1.74061116]\n",
      " [-1.91319595]\n",
      " [-2.43929721]]\n",
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "# Your code to print the sample values in y\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTjU0Q-cxser"
   },
   "source": [
    "# Let's assign the X to a variable Independedent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YdWZQ-b5lDJa"
   },
   "outputs": [],
   "source": [
    "Indpendent_Variables = pd.DataFrame(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gMeaKTBx4-d"
   },
   "source": [
    "# Print Independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "g4ZT1IjrlNHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2    3    4    5\n",
      "0   2.016425  0.560776  2.153944  0.0  1.0  1.0\n",
      "1   1.955874  1.082830  1.923601  1.0  0.0  1.0\n",
      "2   1.754377 -0.728234  1.626528  0.0  0.0  1.0\n",
      "3   1.554797 -0.096342  1.422211  0.0  1.0  1.0\n",
      "4   1.504951 -1.079896  1.281529  0.0  0.0  1.0\n",
      "5   1.279814 -0.776216  1.254211  0.0  1.0  1.0\n",
      "6   1.340080  0.932170 -0.688149  1.0  0.0  1.0\n",
      "7   1.245070  0.872003  0.932187  0.0  0.0  1.0\n",
      "8   1.030382  0.986975  0.830888  0.0  1.0  1.0\n",
      "9   1.091833 -0.456617  0.776108  1.0  0.0  1.0\n",
      "10  0.620412 -0.387576  0.149808  0.0  0.0  1.0\n",
      "11  0.593099 -1.065517  0.319834  1.0  0.0  1.0\n",
      "12  0.443273  0.215472  0.320618  0.0  0.0  1.0\n",
      "13  0.402091  0.510202  0.343958  1.0  0.0  1.0\n",
      "14  1.017194  1.269222  0.375743  0.0  0.0  1.0\n",
      "15  0.897927  0.045891  0.419220  0.0  1.0  1.0\n",
      "16  0.094455  0.009141  0.440447  1.0  0.0  1.0\n",
      "17  0.460734  0.855689  0.591018  0.0  1.0  1.0\n",
      "18  0.396738 -0.258442  0.692993  0.0  0.0  1.0\n",
      "19  0.279455  1.159860 -1.743126  0.0  1.0  1.0\n",
      "20  0.055740 -0.269565  0.723927  1.0  0.0  1.0\n",
      "21  0.102737  1.169209  0.732789  0.0  1.0  1.0\n",
      "22  0.006020  0.051873  0.762377  0.0  0.0  1.0\n",
      "23 -0.136187 -0.562188  0.774350  0.0  0.0  1.0\n",
      "24  0.073128 -0.795446 -0.581938  0.0  1.0  1.0\n",
      "25 -0.199298  0.656512 -0.603516  1.0  0.0  1.0\n",
      "26  0.035384  0.821741 -0.635835  0.0  0.0  1.0\n",
      "27 -0.035505  0.235092  1.174272  0.0  1.0  1.0\n",
      "28 -0.168779  2.210164 -0.767189  0.0  0.0  1.0\n",
      "29 -0.178595  1.142480 -0.858133  0.0  1.0  1.0\n",
      "30 -0.258061 -0.205606 -0.990356  0.0  0.0  1.0\n",
      "31 -0.276945  1.130577 -1.014419  0.0  1.0  1.0\n",
      "32 -0.226935  0.283947 -1.362449  1.0  0.0  1.0\n",
      "33 -0.401115 -0.659301  0.029818  0.0  0.0  1.0\n",
      "34 -0.600669  1.310558 -0.001878  1.0  0.0  1.0\n",
      "35 -0.609736 -1.308634 -0.045492  0.0  1.0  1.0\n",
      "36 -0.991557  0.205948 -0.081762  0.0  0.0  1.0\n",
      "37 -0.652519 -2.525971 -0.115607  1.0  0.0  1.0\n",
      "38 -1.177164 -1.997247 -0.212784  0.0  1.0  1.0\n",
      "39 -0.773807 -1.383099 -0.297582  1.0  0.0  1.0\n",
      "40 -0.989563 -0.100877 -0.315785  1.0  0.0  1.0\n",
      "41 -1.008520 -1.320773 -0.384552  0.0  0.0  1.0\n",
      "42 -1.102092 -0.906914 -0.520595  1.0  0.0  1.0\n",
      "43 -1.281120  0.217705 -1.449604  0.0  1.0  1.0\n",
      "44 -1.134292  1.206442 -1.509073  1.0  0.0  1.0\n",
      "45 -1.600337  0.101277 -1.727399  0.0  1.0  1.0\n",
      "46 -1.593400 -0.199299  0.711123  0.0  0.0  1.0\n",
      "47 -1.622348  0.507745 -1.743126  1.0  0.0  1.0\n",
      "48 -1.610420 -2.509386 -1.743126  0.0  1.0  1.0\n",
      "49 -1.622348 -0.157202 -1.369984  1.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# Your code to print independent variable.\n",
    "print(Indpendent_Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6id_qS-wx_PY"
   },
   "source": [
    "# Following function splits the data into two sets - trainset and testset.\n",
    "# We can also do the same operation using  train_test_split method available in sklearn.model_selection.\n",
    "# But, let's create our own method to split data.\n",
    "\n",
    "# In the following code, set radom_state as your SID.\n",
    "\n",
    "## Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "JyUnKqYklPXO"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size = 0.2, random_state = 2228964):  # Set variable random_state as your SID\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Create a shuffled array of indices for random sampling\n",
    "    indices = np.random.permutation(len(X))\n",
    "\n",
    "    # Calculate the size of the test set\n",
    "    data_test_size = int(X.shape[0] * test_size)\n",
    "\n",
    "    # Split the indices into training and testing sets\n",
    "    train_indices = indices[data_test_size:]\n",
    "    test_indices = indices[:data_test_size]\n",
    "\n",
    "    # Use the indices to extract corresponding data for training and testing\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    # Return the split datasets\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multipleLinearRegression():\n",
    "\n",
    "  def __init__(self):\n",
    "    #No instance Variables required\n",
    "    pass\n",
    "\n",
    "  def forward(self,X,y,W):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    X (array) : Independent Features\n",
    "    y (array) : Dependent Features/ Target Variable\n",
    "    W (array) : Weights\n",
    "\n",
    "    Returns:\n",
    "    loss (float) : Calculated Sqaured Error Loss for y and y_pred\n",
    "    y_pred (array) : Predicted Target Variable\n",
    "    \"\"\"\n",
    "    y_pred = sum(W * X)\n",
    "    loss = ((y_pred-y)**2)/2    #Loss = Squared Error, we introduce 1/2 for ease in the calculation\n",
    "    return loss, y_pred\n",
    "\n",
    "  def updateWeights(self,X,y_pred,y_true,W,alpha,index):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    X (array) : Independent Features\n",
    "    y_pred (array) : Predicted Target Variable\n",
    "    y_true (array) : Dependent Features/ Target Variable\n",
    "    W (array) : Weights\n",
    "    alpha (float) : learning rate\n",
    "    index (int) : Index to fetch the corresponding values of W, X and y\n",
    "\n",
    "    Returns:\n",
    "    W (array) : Update Values of Weight\n",
    "    \"\"\"\n",
    "    for i in range(X.shape[1]):\n",
    "      #alpha = learning rate, rest of the RHS is derivative of loss function\n",
    "      W[i] -= (alpha * (y_pred-y_true[index])*X[index][i])\n",
    "    return W\n",
    "\n",
    "  def train(self, X, y, epochs=10, alpha=0.001, random_state=2187428):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    X (array) : Independent Feature\n",
    "    y (array) : Dependent Features/ Target Variable\n",
    "    epochs (int) : Number of epochs for training, default value is 10\n",
    "    alpha (float) : learning rate, default value is 0.001\n",
    "\n",
    "    Returns:\n",
    "    y_pred (array) : Predicted Target Variable\n",
    "    loss (float) : Calculated Sqaured Error Loss for y and y_pred\n",
    "    \"\"\"\n",
    "\n",
    "    num_rows = X.shape[0] #Number of Rows\n",
    "    num_cols = X.shape[1] #Number of Columns\n",
    "    W = np.random.randn(1,num_cols) / np.sqrt(num_rows) #Weight Initialization\n",
    "\n",
    "    #Calculating Loss and Updating Weights\n",
    "    train_loss = []\n",
    "    num_epochs = []\n",
    "    train_indices = [i for i in range(X.shape[0])]\n",
    "    for j in range(epochs):\n",
    "      cost=0\n",
    "      np.random.seed(random_state)\n",
    "      np.random.shuffle(train_indices)\n",
    "      for i in train_indices:\n",
    "        loss, y_pred = self.forward(X[i],y[i],W[0])\n",
    "        cost+=loss\n",
    "        W[0] = self.updateWeights(X,y_pred,y,W[0],alpha,i)\n",
    "      train_loss.append(cost)\n",
    "      num_epochs.append(j)\n",
    "    return W[0], train_loss, num_epochs\n",
    "\n",
    "  def test(self, X_test, y_test, W_trained):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    X_test (array) : Independent Features from the Test Set\n",
    "    y_test (array) : Dependent Features/ Target Variable from the Test Set\n",
    "    W_trained (array) : Trained Weights\n",
    "    test_indices (list) : Index to fetch the corresponding values of W_trained,\n",
    "                          X_test and y_test\n",
    "\n",
    "    Returns:\n",
    "    test_pred (list) : Predicted Target Variable\n",
    "    test_loss (list) : Calculated Sqaured Error Loss for y and y_pred\n",
    "    \"\"\"\n",
    "    test_pred = []\n",
    "    test_loss = []\n",
    "    test_indices = [i for i in range(X_test.shape[0])]\n",
    "    for i in test_indices:\n",
    "        loss, y_test_pred = self.forward(X_test[i], W_trained, y_test[i])\n",
    "        test_pred.append(y_test_pred)\n",
    "        test_loss.append(loss)\n",
    "    return test_pred, test_loss\n",
    "\n",
    "\n",
    "  def predict(self, W_trained, X_sample):\n",
    "    prediction = sum(W_trained * X_sample)\n",
    "    return prediction\n",
    "\n",
    "  def plotLoss(self, loss, epochs):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    loss (list) : Calculated Sqaured Error Loss for y and y_pred\n",
    "    epochs (list): Number of Epochs\n",
    "\n",
    "    Returns: None\n",
    "    Plots a graph of Loss vs Epochs\n",
    "    \"\"\"\n",
    "    plt.plot(epochs, loss)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Plot Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "vIoOKmLMz7SG"
   },
   "outputs": [],
   "source": [
    "def forward(X, y, theta):\n",
    "\n",
    "    y_pred = np.sum(theta * X)\n",
    "    loss = ((y_pred-y)**2)/2    #This is also the cost function\n",
    "\n",
    "    # Your code to return lost and predicted values.\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ2et9uJ3o4i"
   },
   "source": [
    "# Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "hOrAJ454z8qk"
   },
   "outputs": [],
   "source": [
    "def updateTheta(X, y_pred, y_true, theta, alpha, index):\n",
    "\n",
    "    theta -= alpha *X[index]*(y_pred-y_true[index])\n",
    "    \n",
    "    # Your code to return theta\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "446lDTRr3vA8"
   },
   "source": [
    "## Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "gGC0RCK00TPF"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, epochs=10, alpha=0.001, random_state=0):\n",
    "    # Get the number of rows and columns in the input matrix X\n",
    "    num_rows = X.shape[0]\n",
    "    num_cols = X.shape[1]\n",
    "\n",
    "    # Initialize theta with small random values\n",
    "    theta = np.random.randn(1, num_cols) / np.sqrt(num_rows)\n",
    "\n",
    "    # Lists to store training loss and the corresponding number of epochs\n",
    "    train_loss = []\n",
    "    num_epochs = []\n",
    "\n",
    "    # Generate a list of indices for shuffling during training\n",
    "    train_indices = [i for i in range(X.shape[0])]\n",
    "\n",
    "    # Loop through the specified number of epochs\n",
    "    for j in range(epochs):\n",
    "        # Initialize the cost for this epoch\n",
    "        cost = 0\n",
    "\n",
    "        # Set the random seed for reproducibility\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "        # Shuffle the training indices for each epoch\n",
    "        np.random.shuffle(train_indices)\n",
    "\n",
    "        # Loop through each training instance using the shuffled indices\n",
    "        for i in train_indices:\n",
    "            # Calculate the loss and make predictions using the forward function\n",
    "            loss, y_pred = forward(X[i], y[i], theta)\n",
    "            \n",
    "            # Accumulate the loss for this epoch\n",
    "            cost += loss\n",
    "\n",
    "            # Update theta using the updateTheta function\n",
    "            theta = updateTheta(X[i], y_pred, y, theta, alpha, i)\n",
    "\n",
    "        # Append the total cost for this epoch to the train_loss list\n",
    "        train_loss.append(cost)\n",
    "\n",
    "        # Append the current epoch number to the num_epochs list\n",
    "        num_epochs.append(j)\n",
    "\n",
    "    # Return the final theta, the list of training losses, and the corresponding epoch numbers\n",
    "    return theta, train_loss, num_epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igWtd1Lo3-ep"
   },
   "source": [
    "## Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "DrEpGXdN0Y2q"
   },
   "outputs": [],
   "source": [
    "def test(X_test, y_test, theta_updated):\n",
    "    # Initialize lists to store test predictions and losses\n",
    "    test_pred = []\n",
    "    test_loss = []\n",
    "\n",
    "    # Sample initial values for demonstration purposes (replace with actual values)\n",
    "    test_pred_demo = [200, 300, 500]\n",
    "    test_loss_demo = [0.05, 0.04, 0.02]\n",
    "\n",
    "    # Generate a list of indices for iterating through the test set\n",
    "    test_indices = [i for i in range(X_test.shape[0])]\n",
    "\n",
    "    # Loop through each test instance using the test indices\n",
    "    for i in test_indices:\n",
    "        # Calculate the loss and make predictions using the forward function\n",
    "        loss, y_test_pred = forward(X_test[i], y_test[i], theta_updated)\n",
    "\n",
    "        # Append the predicted value and loss for this test instance\n",
    "        test_pred.append(y_test_pred)\n",
    "        test_loss.append(loss)\n",
    "\n",
    "    # Your code to return the final predictions and losses\n",
    "    return test_pred, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "od4-qZRv4AAf"
   },
   "source": [
    "## Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ORSib6yN0dp5"
   },
   "outputs": [],
   "source": [
    "def predict(theta_updated, X_sample):\n",
    "    # Calculate the prediction using the learned parameters and input sample\n",
    "    prediction = np.sum(theta_updated * X_sample)\n",
    "\n",
    "    # Return the calculated prediction\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrL_oqSeIYO0"
   },
   "source": [
    "# Create a good plot Epochs vs loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "XiryfU2C184a"
   },
   "outputs": [],
   "source": [
    "def plotLoss(loss, epochs):\n",
    "\n",
    "    # Your code to plot epochs vs loss\n",
    "    plt.plot(num_epochs,test_loss)\n",
    "    \n",
    "    # Your code to print x label in the graph\n",
    "    plt.xlabel('Epochs')\n",
    "    # Your code to print y label in the graph\n",
    "    plt.ylabel('Loss')\n",
    "    # Your code to provide title to the plot.\n",
    "    plt.title('Profit of the State')\n",
    "    # Your code to show the plot.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-MpfkCR4IAb"
   },
   "source": [
    "# Calling the method  split_data to get train and test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "EpxMECnipNSd"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD-K1DXW4yjP"
   },
   "source": [
    "# Call the gradient descent function with the number of epochs and learning rate of your choice. Keep number of epochs greater that 200 and learning rate less than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "L6_XGsxmqKEs"
   },
   "outputs": [],
   "source": [
    "model = multipleLinearRegression()\n",
    "W_trained, train_loss, num_epochs = model.train(X_train, y_train, epochs=260, alpha=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEaYqXx5PEx"
   },
   "source": [
    "# Test your regression model using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "WTg11ggFqM6A"
   },
   "outputs": [],
   "source": [
    "# Your code to test the model on test data and updated theta values.\n",
    "test_pred, test_loss =model.test(X_test, y_test, W_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYpIBWt05ZdV"
   },
   "source": [
    "# Plot the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Lq4Ld1cTqQCX"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code to plot epochs vs loss. Call the method.\n",
    "model.plotLoss(train_loss, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eA7JcJ05i3t"
   },
   "source": [
    "Perform the predictions on X_tset. Call predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "bwMj-gm05jqK"
   },
   "outputs": [],
   "source": [
    "# Your code to predict the profit i.e. y values\n",
    "profit_predictions = []\n",
    "for i in range(len(X_test)):\n",
    "    profit_predictions.append(model.predict(W_trained, X_test[i]))\n",
    "\n",
    "# Now, profit_predictions contains all the predicted y values on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QX9qvbBJ5xI"
   },
   "source": [
    "# **Imortant - Lab Logbook requirement:**\n",
    "\n",
    "# Please document the following in your lab logbook:\n",
    "\n",
    "# 1. Plot the loss function.\n",
    "# 2. Record the output of all the predictions on the test data; i.e., all the predicted y values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFVI2Qkt6tJ4"
   },
   "source": [
    "# **Optional Part:**\n",
    "# The rest of this notebook is Optional. It is recommended for you to complete it. However, if you have not marks would not be deducted.\n",
    "\n",
    "# Fitting the model using sklearn and comparing with our model.\n",
    "\n",
    "# Following piece of code is uncommented. Please comment it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhXzFwONqUCV"
   },
   "outputs": [],
   "source": [
    "# Your code to import train_test_split from sklearn.model_selection\n",
    "# Your code to import LinearRegression from sklearn.linear_model\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4JcuB2Lqby_"
   },
   "outputs": [],
   "source": [
    "dataset_sk = pd.read_csv('50_Startups.csv')\n",
    "X_sk = dataset_sk.iloc[:, :-1].values\n",
    "y_sk = dataset_sk.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3npV2v0qgKD"
   },
   "outputs": [],
   "source": [
    "labelencoder_X_sk = LabelEncoder()\n",
    "X_sk[:,3] = labelencoder_X_sk.fit_transform(X_sk[:,3])\n",
    "\n",
    "onehotencoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_sk_categorical = onehotencoder.fit_transform(X_sk[:,3].reshape(-1,1)).toarray()\n",
    "X_sk = np.concatenate((X_sk,X_sk_categorical),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mwGdW42qn3D"
   },
   "outputs": [],
   "source": [
    "X_sk = X_sk[:, [0,1,2,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1l5re-Qqp_o"
   },
   "outputs": [],
   "source": [
    "X_sk.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx5w-R0lqs2Y"
   },
   "outputs": [],
   "source": [
    "# Your code to perform train test split with 20% data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FtPNcs-9qvPo",
    "outputId": "95195c0f-0486-41f7-aa25-39457f73bd70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_sk = LinearRegression()\n",
    "regressor_sk.fit(X_train_sk, y_train_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDTaghDbqyV4"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = regressor_sk.predict(X_test_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQ6Xu0uOq0uf"
   },
   "outputs": [],
   "source": [
    "X_train_sk.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CE6llxNiq30S"
   },
   "outputs": [],
   "source": [
    "#Making the Prediction using Sklearn Regression\n",
    "print(regressor_sk.predict([[160000,140000,5000000,1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90xW5Wcrq6fc"
   },
   "outputs": [],
   "source": [
    "#Making a Prediction\n",
    "pred = predict(theta_updated,[160000,140000,5000000,1,0,1])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCcFXPhO9yYD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
